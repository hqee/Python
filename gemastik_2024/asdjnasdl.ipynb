{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "import torch.nn as LayerOfFear\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch (torch) version = 2.1.2+cu118\n",
    "\n",
    "flag = \"gemastik{REDACTED}\"\n",
    "\n",
    "\n",
    "\n",
    "def convert(ip):\n",
    "\tflag = [float(ord(i)) for i in ip]\n",
    "\tnormalized = torch.tensor([flag], dtype=torch.float32)\n",
    "\treturn normalized\n",
    "\n",
    "def wb(_in,_out):\n",
    "\tweight = np.round(np.random.uniform(-1, 1, (_out, _in)).astype(np.float32),2)\n",
    "\tbias = np.round(np.random.uniform(-1, 1, _out).astype(np.float32),2)\n",
    "\treturn torch.from_numpy(weight), torch.from_numpy(bias)\n",
    "\n",
    "np.random.seed(0x2024)\n",
    "sigma = LayerOfFear.Sequential(\n",
    "\tLayerOfFear.Linear(34, 496),\n",
    "\tLayerOfFear.Linear(496, 128),\n",
    "\tLayerOfFear.Linear(128, 24)\n",
    ")\n",
    "\n",
    "layer_shapes = [(34, 496), (496, 128), (128, 24)]\n",
    "\n",
    "for i, (input_dim, output_dim) in enumerate(layer_shapes):\n",
    "\tweight, bias = wb(input_dim, output_dim)\n",
    "\tsigma[i].weight.data = weight\n",
    "\tsigma[i].bias.data = bias\n",
    " \n",
    "print([i.detach().numpy().tolist() for i in sigma(convert(flag))[0]])\n",
    "# Output:\n",
    "# [4366.66357421875, 32835.87890625, -9967.134765625, 63776.640625, 8547.775390625, 12823.4013671875, 28502.36328125, 5493.84423828125, -38881.9609375, -51316.02734375, 8324.1591796875, -26985.572265625, -28508.75, -18546.349609375, -5972.76904296875, 10322.6025390625, -7311.9833984375, -10486.3115234375, -6370.478515625, 18390.52734375, 41471.14453125, -34282.4921875, -1481.2928466796875, -51079.13671875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
